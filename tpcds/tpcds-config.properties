spark.executor.cores=${NUM_EXECUTOR_CORES}
spark.executor.memory=${EXECUTOR_MEMORY}
spark.driver.memory=${DRIVER_MEMORY}
spark.rapids.memory.host.spillStorageSize=${SPILL_STORAGE_SIZE}
spark.sql.adaptive.enabled=true
spark.sql.files.maxPartitionBytes=${MAXPARTITIONBYTES}
spark.sql.shuffle.partitions=${SHUFFLE_PARTITIONS}
spark.shuffle.consolidateFiles=true
spark.plugins=com.nvidia.spark.SQLPlugin
spark.executor.resource.gpu.amount=1
spark.executor.heartbeatInterval=300s
spark.task.resource.gpu.amount=${RESOURCE_GPU_AMT}
spark.rapids.memory.pinnedPool.size=${PINNED_POOL_SIZE}
spark.rapids.memory.gpu.pool=DEFAULT
spark.rapids.shuffle.transport.enabled=true
spark.rapids.sql.batchSizeRows=2147483647
spark.rapids.sql.explain=ALL
spark.rapids.sql.incompatibleOps.enabled=true
spark.rapids.sql.variableFloatAgg.enabled=true
spark.rapids.sql.concurrentGpuTasks=${CONCURRENTGPU}
spark.rapids.sql.format.parquet.enabled=true
spark.rapids.sql.format.parquet.multiThreadedRead.numThreads=${MULTI_THREADED_READ}
spark.storage.blockManagerSlaveTimeoutMs=3600s
spark.locality.wait=0s
spark.network.timeout=2000s
spark.executor.extraJavaOptions=-Dai.rapids.cudf.prefer-pinned=true\ -Dai.rapids.spark.semaphore.enabled=true\ -Dai.rapids.spark.memory.gpu.rmm.init.task=false
